Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:rocm

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/gpt2                              |      14.471 |             0 |            0 |          0     |       0     |
| pytorch/models/bert-large-uncased                |      27.759 |             0 |            0 |          0     |       0     |
| pytorch/models/phi-1_5                           |      58.914 |             0 |            0 |          0     |       0     |
| pytorch/models/gpt2-xl                           |      79.769 |             0 |            0 |          0     |       0     |
| pytorch/models/dlrm                              |       8.772 |             0 |            0 |          0     |       0     |
| pytorch/models/gemma-7b                          |       2.499 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-hf                      |     220.024 |             0 |            0 |          0     |       0     |
| pytorch/models/mit-b0                            |       7.61  |             0 |            0 |          3.028 |       0.025 |
| pytorch/models/phi-2                             |     113.59  |             0 |            0 |          0     |       0     |
| pytorch/models/mobilebert-uncased                |      26.584 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-GPTQ                    |     504.565 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125M                          |      13.023 |             0 |            0 |          6.118 |       0.026 |
| pytorch/models/vit-base-patch16-224              |       8.232 |             0 |            0 |          2.495 |       0     |
| pytorch/models/whisper-small                     |      13.062 |             0 |            0 |          5.796 |       0.026 |
| pytorch/models/bart-large                        |      13.948 |             0 |            0 |          7.751 |       0.026 |
| pytorch/models/whisper-base                      |       6.596 |             0 |            0 |          2.973 |       0.026 |
| pytorch/models/t5-base                           |      16.824 |             0 |            0 |          4.855 |       0     |
| pytorch/models/opt-350m                          |      20.806 |             0 |            0 |         11.572 |       0.026 |
| pytorch/models/whisper-medium                    |      24.117 |             0 |            0 |         12.516 |       0.025 |
| pytorch/models/bge-base-en-v1.5                  |      14.593 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125m-gptq                     |      27.547 |             0 |            0 |          6.788 |       0.028 |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |       9.973 |             0 |            0 |          0     |       0     |
| pytorch/models/resnet50                          |       6.285 |             0 |            0 |          2.493 |       0     |
| pytorch/models/opt-1.3b                          |      52.226 |             0 |            0 |         38.435 |       0.029 |
| pytorch/models/t5-large                          |      35.591 |             0 |            0 |         13.865 |       0     |
| pytorch/models/miniLM-L12-H384-uncased           |      10.479 |             0 |            0 |          0     |       0     |
| pytorch/models/stablelm-3b-4e1t                  |       2.375 |             0 |            0 |          0     |       0     |
| pytorch/models/deit-small-distilled-patch16-224  |       7.386 |             0 |            0 |          1.746 |       0     |
