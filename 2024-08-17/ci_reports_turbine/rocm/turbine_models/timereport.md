Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:rocm

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/gpt2                              |      13.719 |             0 |            0 |          0     |       0     |
| pytorch/models/bert-large-uncased                |      26.199 |             0 |            0 |          0     |       0     |
| pytorch/models/phi-1_5                           |      59.725 |             0 |            0 |          0     |       0     |
| pytorch/models/gpt2-xl                           |      76.613 |             0 |            0 |          0     |       0     |
| pytorch/models/dlrm                              |       7.871 |             0 |            0 |          0     |       0     |
| pytorch/models/gemma-7b                          |       2.205 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-hf                      |     207.677 |             0 |            0 |          0     |       0     |
| pytorch/models/mit-b0                            |       7.378 |             0 |            0 |          3.349 |       1.012 |
| pytorch/models/phi-2                             |     109.221 |             0 |            0 |          0     |       0     |
| pytorch/models/mobilebert-uncased                |      27.043 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-GPTQ                    |     546.457 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125M                          |      11.169 |             0 |            0 |          5.934 |      10.373 |
| pytorch/models/vit-base-patch16-224              |       8.553 |             0 |            0 |          2.453 |       0     |
| pytorch/models/whisper-small                     |      10.684 |             0 |            0 |          5.534 |      19.641 |
| pytorch/models/bart-large                        |      14.264 |             0 |            0 |          7.58  |      18.67  |
| pytorch/models/whisper-base                      |       6.893 |             0 |            0 |          2.846 |      14.188 |
| pytorch/models/t5-base                           |      17.234 |             0 |            0 |          4.666 |       0     |
| pytorch/models/opt-350m                          |      23.206 |             0 |            0 |         11.284 |      11.712 |
| pytorch/models/whisper-medium                    |      20.121 |             0 |            0 |         12.094 |      20.748 |
| pytorch/models/bge-base-en-v1.5                  |      14.227 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125m-gptq                     |      27.585 |             0 |            0 |          6.592 |      16.482 |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |      10.217 |             0 |            0 |          0     |       0     |
| pytorch/models/resnet50                          |       6.244 |             0 |            0 |          3.521 |       1.027 |
| pytorch/models/opt-1.3b                          |      52.01  |             0 |            0 |         38.054 |      17.209 |
| pytorch/models/t5-large                          |      35.871 |             0 |            0 |         13.4   |       0     |
| pytorch/models/miniLM-L12-H384-uncased           |      10.764 |             0 |            0 |          0     |       0     |
| pytorch/models/stablelm-3b-4e1t                  |       2.383 |             0 |            0 |          0     |       0     |
| pytorch/models/deit-small-distilled-patch16-224  |       7.508 |             0 |            0 |          1.517 |       0     |
