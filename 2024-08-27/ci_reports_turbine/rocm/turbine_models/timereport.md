Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:rocm

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/gpt2                              |      13.113 |             0 |            0 |          0     |       0     |
| pytorch/models/bert-large-uncased                |      25.712 |             0 |            0 |          0     |       0     |
| pytorch/models/phi-1_5                           |      56.233 |             0 |            0 |          0     |       0     |
| pytorch/models/gpt2-xl                           |      75.736 |             0 |            0 |          0     |       0     |
| pytorch/models/dlrm                              |       7.619 |             0 |            0 |          0     |       0     |
| pytorch/models/gemma-7b                          |       2.031 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-hf                      |     199.666 |             0 |            0 |          0     |       0     |
| pytorch/models/mit-b0                            |       6.808 |             0 |            0 |          3.349 |       1.026 |
| pytorch/models/phi-2                             |     108.38  |             0 |            0 |          0     |       0     |
| pytorch/models/mobilebert-uncased                |      26.755 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-GPTQ                    |     526.834 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125M                          |      12.711 |             0 |            0 |          6.324 |      10.163 |
| pytorch/models/vit-base-patch16-224              |       8.707 |             0 |            0 |          2.441 |       0     |
| pytorch/models/whisper-small                     |      10.065 |             0 |            0 |          5.853 |      18.915 |
| pytorch/models/bart-large                        |      14.307 |             0 |            0 |          7.903 |      18.174 |
| pytorch/models/whisper-base                      |       7.015 |             0 |            0 |          3.024 |      13.995 |
| pytorch/models/t5-base                           |      17.52  |             0 |            0 |          5.07  |       0     |
| pytorch/models/opt-350m                          |      16.906 |             0 |            0 |         12.241 |      11.503 |
| pytorch/models/whisper-medium                    |      24.383 |             0 |            0 |         13.07  |      19.592 |
| pytorch/models/bge-base-en-v1.5                  |      14.726 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125m-gptq                     |      23.522 |             0 |            0 |          6.794 |      15.056 |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |      10.24  |             0 |            0 |          0     |       0     |
| pytorch/models/resnet50                          |       6.244 |             0 |            0 |          3.646 |       1.029 |
| pytorch/models/opt-1.3b                          |      53.351 |             0 |            0 |         38.021 |      17.081 |
| pytorch/models/t5-large                          |      37.03  |             0 |            0 |         13.584 |       0     |
| pytorch/models/miniLM-L12-H384-uncased           |      10.642 |             0 |            0 |          0     |       0     |
| pytorch/models/stablelm-3b-4e1t                  |       2.428 |             0 |            0 |          0     |       0     |
| pytorch/models/deit-small-distilled-patch16-224  |       7.6   |             0 |            0 |          1.849 |       0     |
