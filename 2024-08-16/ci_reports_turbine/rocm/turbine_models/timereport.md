Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:rocm

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/gpt2                              |      14.106 |             0 |            0 |          0     |       0     |
| pytorch/models/bert-large-uncased                |      27.344 |             0 |            0 |          0     |       0     |
| pytorch/models/phi-1_5                           |      57.341 |             0 |            0 |          0     |       0     |
| pytorch/models/gpt2-xl                           |      75.309 |             0 |            0 |          0     |       0     |
| pytorch/models/dlrm                              |       7.774 |             0 |            0 |          0     |       0     |
| pytorch/models/gemma-7b                          |       2.155 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-hf                      |     202.012 |             0 |            0 |          0     |       0     |
| pytorch/models/mit-b0                            |       7.476 |             0 |            0 |          3.429 |       1.012 |
| pytorch/models/phi-2                             |     107.806 |             0 |            0 |          0     |       0     |
| pytorch/models/mobilebert-uncased                |      27.664 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-GPTQ                    |     546.437 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125M                          |      10.059 |             0 |            0 |          6.284 |      10.154 |
| pytorch/models/vit-base-patch16-224              |       8.967 |             0 |            0 |          2.44  |       0     |
| pytorch/models/whisper-small                     |      10.233 |             0 |            0 |          6.058 |      17.763 |
| pytorch/models/bart-large                        |      14.269 |             0 |            0 |          8.137 |      16.258 |
| pytorch/models/whisper-base                      |       7.026 |             0 |            0 |          3.138 |      12.119 |
| pytorch/models/t5-base                           |      17.27  |             0 |            0 |          5.262 |       0     |
| pytorch/models/opt-350m                          |      23.821 |             0 |            0 |         12.196 |      10.031 |
| pytorch/models/whisper-medium                    |      25.058 |             0 |            0 |         13.26  |      19.227 |
| pytorch/models/bge-base-en-v1.5                  |      14.597 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125m-gptq                     |      27.531 |             0 |            0 |          6.561 |      16.19  |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |      10.158 |             0 |            0 |          0     |       0     |
| pytorch/models/resnet50                          |       6.238 |             0 |            0 |          3.501 |       1.028 |
| pytorch/models/opt-1.3b                          |      52.812 |             0 |            0 |         40.658 |      16.02  |
| pytorch/models/t5-large                          |      36.124 |             0 |            0 |         15.038 |       0     |
| pytorch/models/miniLM-L12-H384-uncased           |      10.53  |             0 |            0 |          0     |       0     |
| pytorch/models/stablelm-3b-4e1t                  |       2.308 |             0 |            0 |          0     |       0     |
| pytorch/models/deit-small-distilled-patch16-224  |       7.553 |             0 |            0 |          1.592 |       0     |
