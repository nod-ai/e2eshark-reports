Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:rocm

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/gpt2                              |       7.576 |             0 |            0 |              0 |           0 |
| pytorch/models/bert-large-uncased                |      11.529 |             0 |            0 |              0 |           0 |
| pytorch/models/phi-1_5                           |      32.422 |             0 |            0 |              0 |           0 |
| pytorch/models/gpt2-xl                           |      38.044 |             0 |            0 |              0 |           0 |
| pytorch/models/dlrm                              |       8.685 |             0 |            0 |              0 |           0 |
| pytorch/models/gemma-7b                          |       2.199 |             0 |            0 |              0 |           0 |
| pytorch/models/llama2-7b-hf                      |     135.643 |             0 |            0 |              0 |           0 |
| pytorch/models/mit-b0                            |       3.338 |             0 |            0 |              0 |           0 |
| pytorch/models/phi-2                             |      64.453 |             0 |            0 |              0 |           0 |
| pytorch/models/mobilebert-uncased                |       3.483 |             0 |            0 |              0 |           0 |
| pytorch/models/llama2-7b-GPTQ                    |    1377.29  |             0 |            0 |              0 |           0 |
| pytorch/models/opt-125M                          |       7.762 |             0 |            0 |              0 |           0 |
| pytorch/models/vit-base-patch16-224              |       3.312 |             0 |            0 |              0 |           0 |
| pytorch/models/whisper-small                     |       5.052 |             0 |            0 |              0 |           0 |
| pytorch/models/bart-large                        |       7.114 |             0 |            0 |              0 |           0 |
| pytorch/models/whisper-base                      |       3.915 |             0 |            0 |              0 |           0 |
| pytorch/models/t5-base                           |       3.892 |             0 |            0 |              0 |           0 |
| pytorch/models/opt-350m                          |       9.583 |             0 |            0 |              0 |           0 |
| pytorch/models/whisper-medium                    |       8.812 |             0 |            0 |              0 |           0 |
| pytorch/models/bge-base-en-v1.5                  |       7.019 |             0 |            0 |              0 |           0 |
| pytorch/models/opt-125m-gptq                     |      16.992 |             0 |            0 |              0 |           0 |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |       3.576 |             0 |            0 |              0 |           0 |
| pytorch/models/resnet50                          |       2.511 |             0 |            0 |              0 |           0 |
| pytorch/models/opt-1.3b                          |      31.818 |             0 |            0 |              0 |           0 |
| pytorch/models/t5-large                          |       5.522 |             0 |            0 |              0 |           0 |
| pytorch/models/miniLM-L12-H384-uncased           |       5.762 |             0 |            0 |              0 |           0 |
| pytorch/models/stablelm-3b-4e1t                  |       2.384 |             0 |            0 |              0 |           0 |
| pytorch/models/deit-small-distilled-patch16-224  |       3.344 |             0 |            0 |              0 |           0 |
