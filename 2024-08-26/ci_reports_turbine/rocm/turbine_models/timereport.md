Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:rocm

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/gpt2                              |      11.851 |             0 |            0 |          0     |       0     |
| pytorch/models/bert-large-uncased                |      25.384 |             0 |            0 |          0     |       0     |
| pytorch/models/phi-1_5                           |      55.893 |             0 |            0 |          0     |       0     |
| pytorch/models/gpt2-xl                           |      75.806 |             0 |            0 |          0     |       0     |
| pytorch/models/dlrm                              |       7.67  |             0 |            0 |          0     |       0     |
| pytorch/models/gemma-7b                          |       2.086 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-hf                      |     203.537 |             0 |            0 |          0     |       0     |
| pytorch/models/mit-b0                            |       6.845 |             0 |            0 |          3.344 |       1.037 |
| pytorch/models/phi-2                             |     103.559 |             0 |            0 |          0     |       0     |
| pytorch/models/mobilebert-uncased                |      26.598 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-GPTQ                    |     490.356 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125M                          |      13.252 |             0 |            0 |          6.057 |      10.21  |
| pytorch/models/vit-base-patch16-224              |       8.485 |             0 |            0 |          2.408 |       0     |
| pytorch/models/whisper-small                     |      13.184 |             0 |            0 |          5.962 |      18.875 |
| pytorch/models/bart-large                        |      13.956 |             0 |            0 |          7.858 |      18.307 |
| pytorch/models/whisper-base                      |       6.447 |             0 |            0 |          2.89  |      13.749 |
| pytorch/models/t5-base                           |      16.839 |             0 |            0 |          5.217 |       0     |
| pytorch/models/opt-350m                          |      23.429 |             0 |            0 |         12.28  |      11.228 |
| pytorch/models/whisper-medium                    |      19.446 |             0 |            0 |         12.777 |      19.914 |
| pytorch/models/bge-base-en-v1.5                  |      14.297 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125m-gptq                     |      27.201 |             0 |            0 |          6.66  |      15.581 |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |       9.949 |             0 |            0 |          0     |       0     |
| pytorch/models/resnet50                          |       6.132 |             0 |            0 |          3.618 |       0.995 |
| pytorch/models/opt-1.3b                          |      40.741 |             0 |            0 |         38.018 |      16.67  |
| pytorch/models/t5-large                          |      36.884 |             0 |            0 |         13.649 |       0     |
| pytorch/models/miniLM-L12-H384-uncased           |       9.943 |             0 |            0 |          0     |       0     |
| pytorch/models/stablelm-3b-4e1t                  |       2.201 |             0 |            0 |          0     |       0     |
| pytorch/models/deit-small-distilled-patch16-224  |       7.618 |             0 |            0 |          1.841 |       0     |
