Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:rocm

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/gpt2                              |      14.184 |             0 |            0 |          0     |       0     |
| pytorch/models/bert-large-uncased                |      27.335 |             0 |            0 |          0     |       0     |
| pytorch/models/phi-1_5                           |      60.702 |             0 |            0 |          0     |       0     |
| pytorch/models/gpt2-xl                           |      76.584 |             0 |            0 |          0     |       0     |
| pytorch/models/dlrm                              |       7.906 |             0 |            0 |          0     |       0     |
| pytorch/models/gemma-7b                          |       2.349 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-hf                      |     214.081 |             0 |            0 |          0     |       0     |
| pytorch/models/mit-b0                            |       6.818 |             0 |            0 |          3.217 |       1.049 |
| pytorch/models/phi-2                             |     108.515 |             0 |            0 |          0     |       0     |
| pytorch/models/mobilebert-uncased                |      26.97  |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-GPTQ                    |     551.851 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125M                          |       9.731 |             0 |            0 |          5.931 |      10.214 |
| pytorch/models/vit-base-patch16-224              |       8.421 |             0 |            0 |          2.354 |       0     |
| pytorch/models/whisper-small                     |      13.399 |             0 |            0 |          5.529 |      18.053 |
| pytorch/models/bart-large                        |      14.061 |             0 |            0 |          7.362 |      16.873 |
| pytorch/models/whisper-base                      |       6.701 |             0 |            0 |          2.99  |      13.836 |
| pytorch/models/t5-base                           |      17.238 |             0 |            0 |          4.592 |       0     |
| pytorch/models/opt-350m                          |      19.036 |             0 |            0 |         11.697 |      11.4   |
| pytorch/models/whisper-medium                    |      17.957 |             0 |            0 |         12.36  |      19.349 |
| pytorch/models/bge-base-en-v1.5                  |      13.937 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125m-gptq                     |      27.957 |             0 |            0 |          6.588 |      14.264 |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |      10.02  |             0 |            0 |          0     |       0     |
| pytorch/models/resnet50                          |       6.15  |             0 |            0 |          3.453 |       1.02  |
| pytorch/models/opt-1.3b                          |      52.763 |             0 |            0 |         38.119 |      15.19  |
| pytorch/models/t5-large                          |      36.329 |             0 |            0 |         13.564 |       0     |
| pytorch/models/miniLM-L12-H384-uncased           |      10.601 |             0 |            0 |          0     |       0     |
| pytorch/models/stablelm-3b-4e1t                  |       2.333 |             0 |            0 |          0     |       0     |
| pytorch/models/deit-small-distilled-patch16-224  |       7.78  |             0 |            0 |          1.683 |       0     |
