Time (in seconds) report for run: test-turbine using mode:turbine todtype:default backend:rocm

| tests                                            |   model-run |   onnx-import |   torch-mlir |   iree-compile |   inference |
|:-------------------------------------------------|------------:|--------------:|-------------:|---------------:|------------:|
| pytorch/models/gpt2                              |      14.21  |             0 |            0 |          0     |       0     |
| pytorch/models/bert-large-uncased                |      27.78  |             0 |            0 |          0     |       0     |
| pytorch/models/phi-1_5                           |      59.967 |             0 |            0 |          0     |       0     |
| pytorch/models/gpt2-xl                           |      74.907 |             0 |            0 |          0     |       0     |
| pytorch/models/dlrm                              |       8.067 |             0 |            0 |          0     |       0     |
| pytorch/models/gemma-7b                          |       2.443 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-hf                      |     207.672 |             0 |            0 |          0     |       0     |
| pytorch/models/mit-b0                            |       7.102 |             0 |            0 |          3.549 |       1.025 |
| pytorch/models/phi-2                             |     108.064 |             0 |            0 |          0     |       0     |
| pytorch/models/mobilebert-uncased                |      27.366 |             0 |            0 |          0     |       0     |
| pytorch/models/llama2-7b-GPTQ                    |     376.455 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125M                          |      10.143 |             0 |            0 |          6.594 |      10.173 |
| pytorch/models/vit-base-patch16-224              |       8.494 |             0 |            0 |          2.758 |       0     |
| pytorch/models/whisper-small                     |      13.098 |             0 |            0 |          6.057 |      19.316 |
| pytorch/models/bart-large                        |      14.004 |             0 |            0 |          8.29  |      18.24  |
| pytorch/models/whisper-base                      |       6.8   |             0 |            0 |          3.104 |      13.969 |
| pytorch/models/t5-base                           |      17.106 |             0 |            0 |          5.611 |       0     |
| pytorch/models/opt-350m                          |      23.055 |             0 |            0 |         12.84  |      11.43  |
| pytorch/models/whisper-medium                    |      19.535 |             0 |            0 |         13.828 |      19.098 |
| pytorch/models/bge-base-en-v1.5                  |      14.269 |             0 |            0 |          0     |       0     |
| pytorch/models/opt-125m-gptq                     |      27.508 |             0 |            0 |          6.909 |      14.128 |
| pytorch/models/beit-base-patch16-224-pt22k-ft22k |      10.084 |             0 |            0 |          0     |       0     |
| pytorch/models/resnet50                          |       6.076 |             0 |            0 |          3.294 |       1.009 |
| pytorch/models/opt-1.3b                          |      52.717 |             0 |            0 |         38.476 |      15.398 |
| pytorch/models/t5-large                          |      36.532 |             0 |            0 |         13.07  |       0     |
| pytorch/models/miniLM-L12-H384-uncased           |      10.65  |             0 |            0 |          0     |       0     |
| pytorch/models/stablelm-3b-4e1t                  |       2.358 |             0 |            0 |          0     |       0     |
| pytorch/models/deit-small-distilled-patch16-224  |       7.51  |             0 |            0 |          1.647 |       0     |
